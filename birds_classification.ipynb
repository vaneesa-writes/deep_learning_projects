{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "birds_classification.ipynb",
      "provenance": [],
      "mount_file_id": "17V70tkXyxHEhWUACN9lL4yby_s3rVZG6",
      "authorship_tag": "ABX9TyMVJVVuM8bGVFfeFj2oEhM8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaneesa-writes/deep_learning_projects/blob/main/birds_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ta0EugI7U_2f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "wpebPnmAVP5T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(nbr_classes):\n",
        "\n",
        "    base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(229, 229, 3)))\n",
        "\n",
        "    head_model = base_model.output\n",
        "    head_model = Flatten()(head_model)\n",
        "    head_model = Dense(512)(head_model)\n",
        "    head_model = Dropout(0.5)(head_model)\n",
        "    head_model = Dense(nbr_classes, activation=\"softmax\")(head_model)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=head_model)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "JSYDtWMwVP2l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_data_pipelines(batch_size, train_data_path, val_data_path, eval_data_path):\n",
        "\n",
        "    train_augmentor = ImageDataGenerator(\n",
        "        rescale = 1. / 255,\n",
        "        rotation_range=25,\n",
        "        zoom_range=0.15,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.15,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\"\n",
        "    )\n",
        "\n",
        "    val_augmentor = ImageDataGenerator(\n",
        "        rescale = 1. / 255\n",
        "    )\n",
        "\n",
        "    train_generator = train_augmentor.flow_from_directory(\n",
        "        train_data_path,\n",
        "        class_mode=\"categorical\",\n",
        "        target_size=(229,229),\n",
        "        color_mode=\"rgb\",\n",
        "        shuffle=True,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    val_generator = val_augmentor.flow_from_directory(\n",
        "        val_data_path,\n",
        "        class_mode=\"categorical\",\n",
        "        target_size=(229,229),\n",
        "        color_mode=\"rgb\",\n",
        "        shuffle=False,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    eval_generator = val_augmentor.flow_from_directory(\n",
        "        eval_data_path,\n",
        "        class_mode=\"categorical\",\n",
        "        target_size=(229,229),\n",
        "        color_mode=\"rgb\",\n",
        "        shuffle=False,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "\n",
        "    return train_generator, val_generator, eval_generator\n"
      ],
      "metadata": {
        "id": "CXVJaJE5VPzr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_number_of_imgs_inside_folder(directory):\n",
        "\n",
        "    totalcount = 0\n",
        "\n",
        "    for root, dirnames, filenames in os.walk(directory):\n",
        "        for filename in filenames:\n",
        "            _, ext = os.path.splitext(filename)\n",
        "            if ext in [\".png\", \".jpg\", \".jpeg\"]:\n",
        "                totalcount = totalcount + 1\n",
        "\n",
        "    return totalcount"
      ],
      "metadata": {
        "id": "R5efS_4vVPxH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(path_to_data, batch_size, epochs):\n",
        "\n",
        "    path_train_data = os.path.join(path_to_data, 'train')\n",
        "    path_val_data = os.path.join(path_to_data, 'valid')\n",
        "    path_eval_data = os.path.join(path_to_data, 'eval')\n",
        "    print(path_eval_data)\n",
        "\n",
        "    total_train_imgs = get_number_of_imgs_inside_folder(path_train_data)\n",
        "    total_val_imgs = get_number_of_imgs_inside_folder(path_val_data)\n",
        "    total_eval_imgs = get_number_of_imgs_inside_folder(path_eval_data)\n",
        "\n",
        "    print(total_train_imgs, total_val_imgs, total_eval_imgs)\n",
        "    \n",
        "\n",
        "    train_generator, val_generator, eval_generator = build_data_pipelines(\n",
        "        batch_size=batch_size,\n",
        "        train_data_path=path_train_data,\n",
        "        val_data_path=path_val_data,\n",
        "        eval_data_path=path_eval_data\n",
        "    )\n",
        "\n",
        "    classes_dict = train_generator.class_indices\n",
        "\n",
        "    model = build_model(nbr_classes=len(classes_dict.keys()))\n",
        "\n",
        "    optimizer = Adam(lr=1e-5)\n",
        "\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "    ckpt_saver = ModelCheckpoint(\n",
        "        path_to_save_model,\n",
        "        monitor=\"val_accuracy\",\n",
        "        mode='max',\n",
        "        save_best_only=True,\n",
        "        save_freq='epoch',\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=total_train_imgs // batch_size,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=total_val_imgs // batch_size,\n",
        "        epochs=epochs,\n",
        "        callbacks=[ckpt_saver]\n",
        "    )\n",
        "\n",
        "    print(\"[INFO] Evaluation phase...\")\n",
        "\n",
        "    predictions = model.predict_generator(eval_generator)\n",
        "    predictions_idxs = np.argmax(predictions, axis=1)\n",
        "\n",
        "    my_classification_report = classification_report(eval_generator.classes, predictions_idxs, \n",
        "                                                     target_names=eval_generator.class_indices.keys())\n",
        "\n",
        "    my_confusion_matrix = confusion_matrix(eval_generator.classes, predictions_idxs)\n",
        "\n",
        "    print(\"[INFO] Classification report : \")\n",
        "    print(my_classification_report)\n",
        "\n",
        "    print(\"[INFO] Confusion matrix : \")\n",
        "    print(my_confusion_matrix)\n"
      ],
      "metadata": {
        "id": "fqKCPZRCVPun"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    path_to_data = '/content/'\n",
        "    path_to_save_model = '/content/drive/MyDrive/models/birds_weights'\n",
        "    train(path_to_data, 32, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie-0XbVNVPr0",
        "outputId": "7e252b7a-3a8d-4919-8409-205d3c8a2281"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/eval\n",
            "58388 2000 2000\n",
            "Found 58388 images belonging to 400 classes.\n",
            "Found 2000 images belonging to 400 classes.\n",
            "Found 2000 images belonging to 400 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 0s 0us/step\n",
            "87924736/87910968 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1824/1824 [==============================] - ETA: 0s - loss: 4.2813 - accuracy: 0.2005\n",
            "Epoch 1: val_accuracy improved from -inf to 0.63609, saving model to /content/drive/MyDrive/models/birds_weights\n",
            "1824/1824 [==============================] - 771s 414ms/step - loss: 4.2813 - accuracy: 0.2005 - val_loss: 1.6200 - val_accuracy: 0.6361\n",
            "Epoch 2/20\n",
            "1824/1824 [==============================] - ETA: 0s - loss: 2.7653 - accuracy: 0.3976\n",
            "Epoch 2: val_accuracy improved from 0.63609 to 0.75353, saving model to /content/drive/MyDrive/models/birds_weights\n",
            "1824/1824 [==============================] - 755s 414ms/step - loss: 2.7653 - accuracy: 0.3976 - val_loss: 1.0398 - val_accuracy: 0.7535\n",
            "Epoch 3/20\n",
            "1824/1824 [==============================] - ETA: 0s - loss: 2.2949 - accuracy: 0.4850\n",
            "Epoch 3: val_accuracy improved from 0.75353 to 0.81552, saving model to /content/drive/MyDrive/models/birds_weights\n",
            "1824/1824 [==============================] - 762s 418ms/step - loss: 2.2949 - accuracy: 0.4850 - val_loss: 0.7875 - val_accuracy: 0.8155\n",
            "Epoch 4/20\n",
            "1824/1824 [==============================] - ETA: 0s - loss: 2.0235 - accuracy: 0.5408\n",
            "Epoch 4: val_accuracy improved from 0.81552 to 0.82913, saving model to /content/drive/MyDrive/models/birds_weights\n",
            "1824/1824 [==============================] - 747s 410ms/step - loss: 2.0235 - accuracy: 0.5408 - val_loss: 0.6849 - val_accuracy: 0.8291\n",
            "Epoch 5/20\n",
            "1824/1824 [==============================] - ETA: 0s - loss: 1.8566 - accuracy: 0.5720\n",
            "Epoch 5: val_accuracy improved from 0.82913 to 0.84829, saving model to /content/drive/MyDrive/models/birds_weights\n",
            "1824/1824 [==============================] - 741s 406ms/step - loss: 1.8566 - accuracy: 0.5720 - val_loss: 0.6199 - val_accuracy: 0.8483\n",
            "Epoch 6/20\n",
            "1824/1824 [==============================] - ETA: 0s - loss: 1.7159 - accuracy: 0.5995\n",
            "Epoch 6: val_accuracy improved from 0.84829 to 0.86643, saving model to /content/drive/MyDrive/models/birds_weights\n",
            "1824/1824 [==============================] - 756s 414ms/step - loss: 1.7159 - accuracy: 0.5995 - val_loss: 0.5250 - val_accuracy: 0.8664\n",
            "Epoch 7/20\n",
            "1824/1824 [==============================] - ETA: 0s - loss: 1.6151 - accuracy: 0.6206\n",
            "Epoch 7: val_accuracy improved from 0.86643 to 0.88155, saving model to /content/drive/MyDrive/models/birds_weights\n",
            "1824/1824 [==============================] - 754s 414ms/step - loss: 1.6151 - accuracy: 0.6206 - val_loss: 0.4726 - val_accuracy: 0.8816\n",
            "Epoch 8/20\n",
            " 128/1824 [=>............................] - ETA: 11:07 - loss: 1.5735 - accuracy: 0.6384"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-zk9TUBZY3B",
        "outputId": "f0ddf161-858e-4659-dede-75e38ae8cd30"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d gpiosenka/100-bird-species"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFnHve9ZVPpP",
        "outputId": "f5e2f8eb-417a-4d51-da10-c0994aa11a8d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 100-bird-species.zip to /content\n",
            " 99% 1.48G/1.49G [00:12<00:00, 158MB/s]\n",
            "100% 1.49G/1.49G [00:13<00:00, 121MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/100-bird-species.zip"
      ],
      "metadata": {
        "id": "oP5HMsF4VPmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CGD3TyZmVPjk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}